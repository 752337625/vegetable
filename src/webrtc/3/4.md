---
prev: ./3
next: ./5
category:
  - WebRTC
tag:
  - WebRTC
star: 10
---

# WebRTC 基础案例 1

<!-- more -->

## WebRTC 结合 canvas 实现拍照

::: normal-demo WebRTC 结合 canvas 实现拍照

```html
<div>
	<div class="fnButton">
		<button id="open">打开</button>
		<button id="close">关闭</button>
		<button id="photograph">拍照</button>
	</div>
	<div>
		<video id="local" autoplay playsinline></video>
		<canvas id="canvas"></canvas>
	</div>
</div>
```

```js
const open = document.getElementById('open');
const close = document.getElementById('close');
const photograph = document.getElementById('photograph');
const local = document.getElementById('local');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d'); // 获取绘制上下文
let mediaStream = null;
open.onclick = () => {
	if (mediaStream) return;
	// 获取录像
	navigator.mediaDevices.getUserMedia({ audio: true, video: true }).then(stream => {
		mediaStream = stream;
		local.srcObject = stream;
	});
};

close.onclick = () => {
	if (!mediaStream) return;
	mediaStream.getTracks().forEach(track => {
		track.stop();
	});
	local.srcObject = null;
	mediaStream = null;
};

photograph.onclick = () => {
	if (!mediaStream) return;
	ctx.drawImage(local, 0, 0, canvas.width, canvas.height);
};
```

```css
.fnButton {
	margin-bottom: 5px;
}
#local,
#canvas {
	width: 300px;
	height: 300px;
	border: 1px solid;
}
```

:::

## WebRTC 结合 canvas 实现预览

::: normal-demo WebRTC 结合 canvas 实现预览

```html
<div>
	<div class="fnButton">
		<button id="open">打开</button>
		<button id="close">关闭</button>
	</div>
	<div>
		<video id="local" autoplay playsinline></video>
		<canvas id="canvas"></canvas>
	</div>
</div>
```

```js
const open = document.getElementById('open');
const close = document.getElementById('close');
const photograph = document.getElementById('photograph');
const local = document.getElementById('local');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d'); // 获取绘制上下文
let c = null;
let mediaStream = null;
open.onclick = () => {
	if (mediaStream) return;
	// 获取录像
	navigator.mediaDevices.getUserMedia({ audio: true, video: true }).then(stream => {
		mediaStream = stream;
		local.srcObject = stream;
		animationFrame();
	});
};
let animationFrame = () => {
	ctx.drawImage(local, 0, 0, canvas.width, canvas.height);
	c = requestAnimationFrame(animationFrame);
};
close.onclick = () => {
	if (!mediaStream) return;
	mediaStream.getTracks().forEach(track => {
		track.stop();
	});
	local.srcObject = null;
	mediaStream = null;
	cancelAnimationFrame(c);
	c = null;
};
```

```css
.fnButton {
	margin-bottom: 5px;
}
#local,
#canvas {
	width: 300px;
	height: 300px;
	border: 1px solid;
}
```

:::

## WebRTC 结合 canvas 实现预览+滤镜

::: normal-demo WebRTC 结合 canvas 实现预览+滤镜

```html
<div>
	<div class="fnButton">
		<button id="open">打开</button>
		<button id="close">关闭</button>
	</div>
	<div class="fnButton">
		<select id="filter">
			<option value="none">None</option>
			<option value="blur">Blur</option>
			<option value="grayscale">Grayscale</option>
			<option value="invert">Invert</option>
			<option value="sepia">Sepia</option>
		</select>
	</div>
	<div>
		<video id="local" autoplay playsinline></video>
		<canvas id="canvas"></canvas>
	</div>
</div>
```

```js
const open = document.getElementById('open');
const close = document.getElementById('close');
const photograph = document.getElementById('photograph');
const local = document.getElementById('local');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d'); // 获取绘制上下文
const filterSelect = document.querySelector('select#filter');
let c = null;
let mediaStream = null;
filterSelect.onchange = function () {
	local.className = filterSelect.value;
	canvas.className = filterSelect.value;
};
open.onclick = () => {
	if (mediaStream) return;
	// 获取录像
	navigator.mediaDevices.getUserMedia({ audio: true, video: true }).then(stream => {
		mediaStream = stream;
		local.srcObject = stream;
		animationFrame();
	});
};
let animationFrame = () => {
	ctx.drawImage(local, 0, 0, canvas.width, canvas.height);
	c = requestAnimationFrame(animationFrame);
};
close.onclick = () => {
	if (!mediaStream) return;
	mediaStream.getTracks().forEach(track => {
		track.stop();
	});
	local.srcObject = null;
	mediaStream = null;
	cancelAnimationFrame(c);
	c = null;
};
```

```css
.fnButton {
	margin-bottom: 5px;
}
#local,
#canvas {
	width: 300px;
	height: 300px;
	border: 1px solid;
}
.none {
	filter: none;
}

.blur {
	filter: blur(3px);
}

.grayscale {
	filter: grayscale(1);
}

.invert {
	filter: invert(1);
}

.sepia {
	filter: sepia(1);
}
```

:::

## WebRTC 结合 canvas 实现虚拟背景（人工背景绿色）

::: normal-demo WebRTC 结合 canvas 实现虚拟背景（人工背景绿色）

```html
<div>
	<div class="fnButton">
		<button id="open">打开</button>
		<button id="close">关闭</button>
	</div>
	<div>
		<video id="local" autoplay playsinline></video>
		<canvas id="backgroundImg"></canvas>
		<canvas id="canvas"></canvas>
		<canvas id="virtual"></canvas>
	</div>
</div>
```

```js
const open = document.getElementById('open');
const close = document.getElementById('close');
const photograph = document.getElementById('photograph');
const local = document.getElementById('local');
const canvas = document.getElementById('canvas');
const virtual = document.getElementById('virtual');
const ctx = canvas.getContext('2d'); // 获取绘制上下文
const virtualctx = virtual.getContext('2d'); // 获取绘制上下文
let c = null;
let mediaStream = null;
let realVideoImageData = null;
let backgroundImageData = null;
open.onclick = () => {
	if (mediaStream) return;
	navigator.mediaDevices.getUserMedia({ audio: true, video: true }).then(stream => {
		mediaStream = stream;
		local.srcObject = stream;
		animationFrame();
	});
};
let processFrameDrawToVirtualVideo = () => {
	for (let i = 0; i < realVideoImageData.data.length; i += 4) {
		const r = realVideoImageData.data[i];
		const g = realVideoImageData.data[i + 1];
		const b = realVideoImageData.data[i + 2];
		const a = realVideoImageData.data[i + 3];
		const bgR = backgroundImageData.data[i];
		const bgG = backgroundImageData.data[i + 1];
		const bgB = backgroundImageData.data[i + 2];
		const bgA = backgroundImageData.data[i + 3];
		const diff = colorDiff([r, g, b], [255, 255, 255]);
		if (diff < 50) {
			realVideoImageData.data[i] = bgR;
			realVideoImageData.data[i + 1] = bgG;
			realVideoImageData.data[i + 2] = bgB;
			realVideoImageData.data[i + 3] = bgA;
		}
	}
	virtualctx.putImageData(realVideoImageData, 0, 0);
};
let colorDiff = (rgba1 = [], rgba2 = []) => {
	let d = 0;
	for (let i = 0; i < rgba1.length; i++) {
		d += (rgba1[i] - rgba2[i]) ** 2;
	}
	return Math.sqrt(d);
};
let animationFrame = () => {
	ctx.drawImage(local, 0, 0, canvas.width, canvas.height);
	realVideoImageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
	processFrameDrawToVirtualVideo();
	c = requestAnimationFrame(animationFrame);
};
close.onclick = () => {
	if (!mediaStream) return;
	mediaStream.getTracks().forEach(track => {
		track.stop();
	});
	local.srcObject = null;
	mediaStream = null;
	cancelAnimationFrame(c);
	c = null;
};
let getBackgroundImageData = () => {
	const backgroundCanvas = document.querySelector('#backgroundImg');
	const backgroundCtx = backgroundCanvas.getContext('2d');
	const img = new Image();
	img.src = '/hero.jpg';
	img.onload = () => {
		backgroundCtx.drawImage(img, 0, 0, backgroundCanvas.width, backgroundCanvas.height);
		backgroundImageData = backgroundCtx.getImageData(
			0,
			0,
			backgroundCanvas.width,
			backgroundCanvas.height,
		);
	};
};
getBackgroundImageData();
```

```css
.fnButton {
	margin-bottom: 5px;
}
#local,
#canvas,
#virtual,
#backgroundImg {
	width: 200px;
	height: 200px;
	border: 1px solid;
}
```

:::
