---
prev: false
next: ./2
category:
  - WebRTC
tag:
  - WebRTC
star: 1
---

# WebRTC 概览

在 WebRTC 诞生之前，实时通信技术是复杂的，想要获取核心的音视频编码及传输技术价格过于昂贵。此外，将实时通信技术与业务结合也很困难，耗时。通常只有大公司才有能力实现。

<!-- more -->

## WebRTC 的历史

- 2010 年 5 月，Google 以 6820 万美元收购 VoIP 软件开发商 Global IP Solutions 的 GIPS 引擎，并改为名为“WebRTC”。WebRTC 使用 GIPS 引擎，实现了基于网页的视频会议，并支持 722，PCM，ILBC，ISAC 等编码，同时使用谷歌自家的 VP8 视频解码器；同时支持 RTP/SRTP 传输等。
- 谷歌 2011 年 6 月 3 日宣布向开发人员开放 WebRTC 架构的源代码。这个源代码将根据没有专利费的 BSD（伯克利软件发布）式的许可证向用户提供。开发人员可访问并获取 WebRTC 的源代码、规格说明和工具等。 [2]
- Google Chrome：2012 年 1 月，将 WebRTC 集成进 Dev Channel，同年 6 月又完成 Stable Channel 的 20 版的集成（2012 年 7 月，PeerConnection 与 MediaStream 仍必须透过 chrome://flags page 来打开）。
- Mozilla Firefox：2012 年初 Mozilla 集成 WebRTC 入 Firefox Alpha，此一版本的 Audio Mixing 已完成于 Media Stream。
- 2012 年 1 月，谷歌已经把这款软件集成到 Chrome 浏览器中。同时 FreeSWITCH 项目宣称支持 iSAC audio codec。
- 2012 年 4 月，Mozilla 展示 Firefox 中 WebRTC 的视频对话。
- 2013 年 6 月，发布 22.0 版本正式集成及支持 WebRTC。
- 2013 年 9 月，发布 24.0 版本，并宣布 Firefox for Android（移动版）正式集成及支持 WebRTC。
- Opera：2012 年 1 月，Opera 初步集成 WebRTC。
- Internet Explorer：Microsoft 开始开放 API。
- Ericsson：2012 年 11 月，Ericsson Labs 做出了全世界第一个可以支持 WebRTC 的手机浏览器。
- SeaMonkey：2013 年 1 月发布的 15.0 版本初步集成 WebRTC。
- 2019 年 10 月 22 日，W3C WebRTC 工作组（Web Real-Time Communications Working Group）发布 WebRTC 可伸缩视频编码（SVC）扩展（Scalable Video Coding (SVC) Extension for WebRTC）的首个公开工作草案（First Public Working Draft）。 文档定义了 WebIDL 中的一组 ECMAScript APIs 来扩展 WebRTC 1.0 API，以允许用户代理支持可伸缩视频编码（SVC）。
- 2022 年 3 月 15 日，W3C 媒体工作组发布自动播放策略检测（Autoplay Policy Detection）规范的首个公开工作草案。该规范为开发者提供了一种能力，用以探测在不同情况下是否允许自动开始播放媒体文件。欢迎公众通过 Github 反馈对该文档的意见与建议。

## WebRTC 的技术架构

从技术角度考虑，在浏览器之间进行实时通信需要很多技术支持，如媒体数据实时传输、音视频编码、网络连接管理等，还需要提供一组易用的 API 给开发者使用。这些技术组合在一起，就是 WebRTC 技术架构。

![WebRTC技术架构](./img/webrtc.webp 'WebRTC技术架构')

WebRTC 技术架构的顶层分为：一部分是 Web API，一组 JavaScript 接口，由 W3C 维护，开发人员可以使用这些 API 在浏览器中创建实时通信应用程序。另一部分是适用于移动端及桌面开发的 libwebrtc，即使用 WebRTC C++源码在 Windows、Android、iOS 等平台编译后的开发包，开发人员可以使用这个开发包打造原生的 WebRTC 应用程序。  
WebRTC 技术架构的第二层：WebRTC C++API,它是 Web API 和 libwebrtc 的底层实现。该层包含了连接管理、连接设置、会话状态和数据传输的 API。基于这些 API，浏览器厂商可以方便地加入对 WebRTC 的支持。  
WebRTC 技术架构的第三层：会话管理,WebRTC 在两个 Peer 之间通信之前需要创建一个 Session。这一层就负责 session 的创建、管理。
WebRTC 规范里没有包含信令协议，这部分需要研发人员依据业务特点自行实现。  
WebRTC 技术架构的第四层：

- 音频引擎（VoiceEngine）负责 WebRTC 的音频采集、编解码、传输控制和音频信号处理。音频编解码部分支持 iSAC 和 iLBC，语音信号处理部分支持回声消除(AcousticEchoCancceler，AEC)和降噪(NoiseReduction，NR)。
- 视频引擎（VideoEngine）负责 WebRTC 的视频采集、编解码、流控和图像信号处理。视频图像编解码部分支持 VP8、H264（默认是 VP8）。视频图像处理部分是对采集到的图像进行颜色增强、降噪等处理来提升图像清晰度，流控部分是使用 jetter buffer 和 FEC 来减小网络抖动和丢包带来的影响。
- 网络传输负责音视频数据和应用数据的传输，在应用层媒体数据（音频、视频等）使用 Secure Real-time Transport Protocol (SRTP) 传输，而非媒体数据（文字、图片等）使用 Stream Control Transmission Protocol (SCTP)传输。在传输层使用 UDP 协议。而在应用层和传输层之间，WebRTC 使用 DTLS(Datagram Transport Layer Security) 解决 UDP 网络传输的安全机制。另外还通过整合了 STUN 和 TURN 的 ICE 协议来实现 NAT 转换和公网穿透。

## WebRTC 的网路拓扑

### **Mesh 网络结构**

Mesh 是 WebRTC 多方会话最简单的网络结构。在这种结构中，每个参与者都向其他所有参与者发送媒体流，同时接收其他所有参与者发送的媒体流。说这是最简单的网络结构，是因为它是 Web-RTC 原生支持的，无须媒体服务器的参与。Mesh 网络结构如下图所示:  
 ![Mesh 网络结构  ](./img/mesh.webp 'Mesh网络结构')
**缺点：** 在 Mesh 网络结构中，每个参与者都以 P2P 的方式相互连接，数据交换基本不经过中央服务器（部分无法使用 P2P 的场景，会经过 TURN 服务器）。由于每个参与者都要为其他参与者提供独立的媒体流，因此需要 N-1 个上行链路和 N-1 个下行链路。众多上行和下行链路限制了参与人数，参与人过多会导致明显卡顿，通常只能支持 6 人以下的实时互动场景。

由于没有媒体服务器的参与，Mesh 网络结构难以对视频做额外的处理，不支持视频录制、视频转码、视频合流等操作。

### **MCU 网络结构**

MCU（Multipoint Control Unit）是一种传统的中心化网络结构，参与者仅与中心的 MCU 媒体服务器连接。MCU 媒体服务器合并所有参与者的视频流，生成一个包含所有参与者画面的视频流，参与者只需要拉取合流画面。
![MCU 网络结构  ](./img/mcu.webp 'MCU 网络结构')  
**优点：** 这种场景下，每个参与者只需要 1 个上行链路和 1 个下行链路。与 Mesh 网络结构相比，参与者所在的终端压力要小很多，可以支持更多人同时在线进行音视频通信，比较适合多人实时互动场景。

**缺点：** 但是 MCU 服务器负责所有视频编码、转码、解码、合流等复杂操作，服务器端压力较大，需要较高的配置。同时由于合流画面固定，界面布局也不够灵活。

### **SFU 网络结构**

在 SFU（Selective Forwarding Unit）网络结构中，仍然有中心节点媒体服务器，但是中心节点只负责转发，不做合流、转码等资源开销较大的媒体处理工作，所以服务器的压力会小很多，服务器配置也不像 MCU 的要求那么高。每个参与者需要 1 个上行链路和 N-1 个下行链路，带宽消耗低于 Mesh，但是高于 MCU。

我们可以将 SFU 服务器视为一个 WebRTC 参与方，它与其他所有参与方进行 1 对 1 的建立连接，并在其中起到桥梁的作用，同时转发各个参与者的媒体数据。SFU 服务器具备复制媒体数据的能力，能够将一个参与者的数据转发给多个参与者。

SFU 服务器与 TURN 服务器不同，TURN 服务器仅仅是为 WebRTC 客户端提供的一种辅助转发通道，在无法使用 P2P 的情况下进行透明的数据转发，TURN 服务器不具备复制、转发媒体数据的能力。

SFU 对参与实时互动的人数也有一定的限制，适用于在线教学、大型会议等场景，其网络结构见下图:
![SFU 网络结构  ](./img/sfu.webp 'SFU 网络结构')

### **Simulcast 联播**

如何确保会话质量？使用 MUC 时，这个问题相对简单一些。MUC 可以个呢根据参与者的网路质量和设备能力，提供不同的清晰度和码率。但是随之而来的是服务端压力较大，难以支撑大规模并发，同时也显著增加了使用成本。

而多人会话场景选择 SFU 网络结构是目前通用的做法。早期 SFU 只是将媒体流从发送端转发给接收端，无法独立为不同参与者调整视频码率，其结果是发送者需要自行调整码率，以适应接收条件差的参与者。而最后导致网络环境好的也接收到相同质量的媒体流。

Simulcast 技术对 SFU 进行了优化，发送端可以同时发送多个不同质量的媒体流给接收端。SFU 能够依据参与者的网络质量，决定转发给参与者哪种质量的媒体流。

**缺点：** 因为发送者需要发送多个不同质量的媒体流，所以会显著增加发送设备的载荷，同时占用发送者上行带宽资源。

### **可伸缩视频编码**

可伸缩视频编码（Scalable Video Coding, SVC）是 Simulcast 改进技术。它使用分层编码技术，发送端只需要发送一个独立视频流给 SFU，SFC 采用这种技术根据不同的层，编码出不同质量的视频流，最后 SFC 发送给不同接收条件的参与者。

可伸缩视频编码（Scalable Video Coding, SVC）是视频编码的一种，该技术把视频信号编码成分层的形式，当带宽不足时只对基本层的码流进行传输和解码，但这时解码的视频质量不高。当带宽慢慢变大时，可以传输和解码增强层的码流来提高视频的解码质量。

可伸缩的直观体现，显然是在码率上。而视频数据的分层编码和选择传输是实现可伸缩的主要手段。

所谓分层编码，就是在时间，空间，质量上进行划分，输出多层码流(包括基本层和增强层)，其中基本层的数据可以使解码器完全正常的解码出基本视频内容，但是基本层的数据获得的视频图像可能帧率较低，分辨率较低，或者质量较低。在信道受限或信道环境复杂时，可以保证解码端能够接收到可以观看的流畅视频图像。当信道环境良好或信道资源丰富时，可以传递增强层数据，以提高帧率，或分辨率，或视频质量。而增强层是可以多层编码的，这就意味着，在视频码流总码率的范围内，接收到的码率越大，视频质量越好。

相对于原来的视频编码标准，一次编码后的视频码流就固定了，对于不同的终端应用，需要对同一内容多次编码，可伸缩视频编码有效的解决了之前编码标准输出码流的不灵活性，一次编码，可以适应多种不同信道。

SVC 编码器能提供一个单独的多层嵌套码流.从这个码流中可以抽取些子码流来满足不同的需求，子码流可以是较低的帧率和空间分辨率.或者在帧率和空间分辨率相同的情况下不同的比特率(也就是不同的视频主客观质量)。一般说来，子码流能满足网络传输速率及终端用户和设备对视频在空间、时间和质量等方面的需求。需要注意的是:编码多组单层码流该方法被称作同播(simulcasting))也能解决该图中的问题。但是，因为码流之间没有联系，它们的冗余没有被去除，所以存储和传输多组码流会带来较大代价。此外，编码单层码流并使用转码技术将该单层码流转为多组其他所需码流，但是转码过程会增加计算复杂度，且降低码流率失真性能。

## WebRTC 兼容性

### 浏览器

**PC 端：**

- Chrome 23+，部分大于 23+的浏览器需要添加前缀;
- Edge 15+，部分大于 15+的浏览器 not support RTCDataChannel;
- Safari 11+;
- Firefox 22+，部分大于 22+的的浏览器需要添加前缀;
- Opera 18+，部分大于 18+的的浏览器需要添加前缀;
- IE 完全不支持;

**注意：对于前缀我们可以使用[adapter](https://github.com/webrtc/adapter)**

**移动端下载浏览器：**

- Chrome for Android 107
- Firefox for Android 106
- UC Browser for Android 13.4
- QQ Browser 13.1
- 如果你在 iOS 上使用任何其他浏览器，是无法使用 WebRTC 的。因为苹果还没有在 iOS 的 Webkit Webview 中提供 WebRTC，所以他们不允许任何人构建不使用 Webkit 作为其渲染引擎的手机 iOS 浏览器。

![WebRTC](./img/caniuse.jpg 'WebRTC兼容性')

**WebView：**

- Android Browser 5+
- Safari on iOS 11+  
  自 Safari 11 以来，iOS Safari 一直支持 WebRTC 使用。  
  现在 iOS 版本更到了 Safari 13.5 以上，但仍然没能实现真正支持 WebRTC。  
  **iOS Safari WebRTC 真是一团糟。所以我向客户提出的建议是不支持它，并将用户重定向到本机应用程序安装。** 因为我必须手动检查 webkit 中所有未解决的 WebRTC 错误，才能弄清楚如何向我的客户解释这一点，帮助他们解决问题，甚至还要和他们自己的客户沟通。  
  从 2019 年或更早以来，iOS Safari 就存在一些 WebRTC 媒体处理相关的 bug。这些 bug 不都是罕见问题，很多都是用户经常在使用时会遇到的问题。其中一些 bug 终于在 2020 年 7 月最新的 13.5.5 beta 中得到修复。  
  如果你在 iOS 上使用任何其他浏览器，是无法使用 WebRTC 的。因为苹果还没有在 iOS 的 Webkit Webview 中提供 WebRTC，所以他们不允许任何人构建不使用 Webkit 作为其渲染引擎的手机 iOS 浏览器。  
  到目前为止，还没有很好的方法可以在 iOS Safari 中大规模运行 WebRTC Web 应用程序。希望将来能解决这一问题

### 移动端原生（Android 和 iOS）

完全没问题

## WebRTC 可以做什么

![WebRTC](./img/webrtc.png 'WebRTC PC端和移动端浏览器支持情况')

## WebRTC 目录结构

![WebRTC项目目录](./img/webrtcsrc.png 'WebRTC项目目录')
